{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước của DataFrame sau khi merge:\n",
      "Số lượng dòng: 19891\n",
      "Số lượng cột: 8\n",
      "\n",
      "Danh sách các cột:\n",
      "['title', 'original_url', 'thumbnail_url', 'source_website', 'resolution', 'search_query', 'page_number', 'local_path']\n"
     ]
    }
   ],
   "source": [
    "# Đọc các file CSV\n",
    "df1 = pd.read_csv(os.path.join('./csv/traffic_images_dataset_v1.csv'))\n",
    "df2 = pd.read_csv(os.path.join('./csv/traffic_images_dataset_v2.csv'))\n",
    "\n",
    "# Merge 2 dataframe\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Hiển thị kích thước của DataFrame\n",
    "print(f\"Kích thước của DataFrame sau khi merge:\")\n",
    "print(f\"Số lượng dòng: {merged_df.shape[0]}\")\n",
    "print(f\"Số lượng cột: {merged_df.shape[1]}\")\n",
    "\n",
    "# Hiển thị tên các cột\n",
    "print(\"\\nDanh sách các cột:\")\n",
    "print(merged_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Số lượng URL trùng lặp: 7404\n",
      "\n",
      "Số lượng giá trị null trong mỗi cột:\n",
      "title                0\n",
      "original_url         0\n",
      "thumbnail_url        0\n",
      "source_website       0\n",
      "resolution           0\n",
      "search_query         0\n",
      "page_number          0\n",
      "local_path        3119\n",
      "dtype: int64\n",
      "\n",
      "Kích thước DataFrame sau khi lọc:\n",
      "Ban đầu: (19891, 8)\n",
      "Sau khi lọc trùng lặp: (12487, 8)\n",
      "Sau khi lọc null: (10840, 8)\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra số lượng URL trùng lặp\n",
    "duplicate_urls = merged_df[merged_df.duplicated(subset=['original_url'], keep='first')]\n",
    "print(f\"\\nSố lượng URL trùng lặp: {len(duplicate_urls)}\")\n",
    "\n",
    "# Kiểm tra số lượng giá trị null trong từng cột\n",
    "print(\"\\nSố lượng giá trị null trong mỗi cột:\")\n",
    "print(merged_df.isnull().sum())\n",
    "\n",
    "# Lọc bỏ các dòng trùng lặp (giữ lại dòng đầu tiên)\n",
    "merged_df_no_duplicates = merged_df.drop_duplicates(subset=['original_url'], keep='first')\n",
    "\n",
    "# Lọc bỏ các dòng có giá trị null\n",
    "merged_df_clean = merged_df_no_duplicates.dropna()\n",
    "\n",
    "# Hiển thị kích thước của DataFrame sau khi lọc\n",
    "print(f\"\\nKích thước DataFrame sau khi lọc:\")\n",
    "print(f\"Ban đầu: {merged_df.shape}\")\n",
    "print(f\"Sau khi lọc trùng lặp: {merged_df_no_duplicates.shape}\")\n",
    "print(f\"Sau khi lọc null: {merged_df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Danh sách các cột sau khi xử lý:\n",
      "['original_url', 'source_website', 'resolution', 'search_query', 'local_path', 'short_caption']\n",
      "\n",
      "Kích thước DataFrame cuối cùng: (10840, 6)\n",
      "\n",
      "5 dòng đầu tiên của DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_url</th>\n",
       "      <th>source_website</th>\n",
       "      <th>resolution</th>\n",
       "      <th>search_query</th>\n",
       "      <th>local_path</th>\n",
       "      <th>short_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://cand.com.vn/Files/Image/chienthang/202...</td>\n",
       "      <td>Công an Nhân dân</td>\n",
       "      <td>600x400</td>\n",
       "      <td>vỉa hè đường phố việt nam</td>\n",
       "      <td>images/vỉa hè đường phố việt nam_1736910371.jpg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://cafebiz.cafebizcdn.vn/1621233102540021...</td>\n",
       "      <td>CafeBiz</td>\n",
       "      <td>2000x1500</td>\n",
       "      <td>vỉa hè đường phố việt nam</td>\n",
       "      <td>images/vỉa hè đường phố việt nam_1736910372.jpg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://cdn.tiasang.com.vn/tiasang-media/2023/...</td>\n",
       "      <td>Tạp chí Tia sáng</td>\n",
       "      <td>1901x1271</td>\n",
       "      <td>vỉa hè đường phố việt nam</td>\n",
       "      <td>images/vỉa hè đường phố việt nam_1736910372.jpg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://cand.com.vn/Files/Image/chienthang/202...</td>\n",
       "      <td>Công an Nhân dân</td>\n",
       "      <td>660x451</td>\n",
       "      <td>vỉa hè đường phố việt nam</td>\n",
       "      <td>images/vỉa hè đường phố việt nam_1736910372.jpg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://icdn.dantri.com.vn/thumb_w/680/dansinh...</td>\n",
       "      <td>Dân sinh - Dân trí</td>\n",
       "      <td>680x454</td>\n",
       "      <td>vỉa hè đường phố việt nam</td>\n",
       "      <td>images/vỉa hè đường phố việt nam_1736910372.jpg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        original_url      source_website  \\\n",
       "0  https://cand.com.vn/Files/Image/chienthang/202...    Công an Nhân dân   \n",
       "1  https://cafebiz.cafebizcdn.vn/1621233102540021...             CafeBiz   \n",
       "2  https://cdn.tiasang.com.vn/tiasang-media/2023/...    Tạp chí Tia sáng   \n",
       "3  https://cand.com.vn/Files/Image/chienthang/202...    Công an Nhân dân   \n",
       "4  https://icdn.dantri.com.vn/thumb_w/680/dansinh...  Dân sinh - Dân trí   \n",
       "\n",
       "  resolution               search_query  \\\n",
       "0    600x400  vỉa hè đường phố việt nam   \n",
       "1  2000x1500  vỉa hè đường phố việt nam   \n",
       "2  1901x1271  vỉa hè đường phố việt nam   \n",
       "3    660x451  vỉa hè đường phố việt nam   \n",
       "4    680x454  vỉa hè đường phố việt nam   \n",
       "\n",
       "                                        local_path short_caption  \n",
       "0  images/vỉa hè đường phố việt nam_1736910371.jpg                \n",
       "1  images/vỉa hè đường phố việt nam_1736910372.jpg                \n",
       "2  images/vỉa hè đường phố việt nam_1736910372.jpg                \n",
       "3  images/vỉa hè đường phố việt nam_1736910372.jpg                \n",
       "4  images/vỉa hè đường phố việt nam_1736910372.jpg                "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chọn các cột cần thiết\n",
    "selected_columns = ['original_url', 'source_website', 'resolution', 'search_query', 'local_path']\n",
    "final_df = merged_df_clean[selected_columns].copy()\n",
    "\n",
    "# Thêm cột short_caption mới (khởi tạo với giá trị rỗng)\n",
    "final_df['short_caption'] = ''\n",
    "\n",
    "# Hiển thị thông tin về DataFrame sau khi xử lý\n",
    "print(\"Danh sách các cột sau khi xử lý:\")\n",
    "print(final_df.columns.tolist())\n",
    "print(f\"\\nKích thước DataFrame cuối cùng: {final_df.shape}\")\n",
    "\n",
    "# Hiển thị 5 dòng đầu tiên để kiểm tra\n",
    "print(\"\\n5 dòng đầu tiên của DataFrame:\")\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "\n",
    "# Thêm warning ignore cho SSL verification\n",
    "import warnings\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# Tạo thư mục để lưu ảnh nếu chưa tồn tại\n",
    "image_dir = './images'\n",
    "if not os.path.exists(image_dir):\n",
    "    os.makedirs(image_dir)\n",
    "\n",
    "def download_image(url, save_path, max_retries=3):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                url,\n",
    "                headers=headers,\n",
    "                timeout=15,  # Tăng timeout\n",
    "                verify=False,  # Bỏ qua SSL verification\n",
    "                stream=True  # Stream response để xử lý file lớn\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                # Kiểm tra content-type\n",
    "                if 'image' in response.headers.get('content-type', ''):\n",
    "                    with open(save_path, 'wb') as f:\n",
    "                        for chunk in response.iter_content(chunk_size=8192):\n",
    "                            if chunk:\n",
    "                                f.write(chunk)\n",
    "                    return True\n",
    "                else:\n",
    "                    print(f\"URL không trả về ảnh: {url}\")\n",
    "                    return False\n",
    "            else:\n",
    "                print(f\"Lỗi HTTP {response.status_code} cho URL: {url}\")\n",
    "                \n",
    "        except requests.exceptions.SSLError:\n",
    "            print(f\"Lỗi SSL với {url}, đang thử lại...\")\n",
    "            continue\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"Timeout với {url}, đang thử lại...\")\n",
    "            continue\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            print(f\"Lỗi kết nối với {url}, đang thử lại...\")\n",
    "            time.sleep(2)  # Đợi thêm thời gian trước khi thử lại\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi không xác định khi tải {url}: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    print(f\"Đã thử {max_retries} lần nhưng không thành công: {url}\")\n",
    "    return False\n",
    "\n",
    "\n",
    "# Lấy 200 ảnh đầu tiên để demo\n",
    "sample_df = final_df.head(500).copy()\n",
    "\n",
    "# Tạo tên file mới dựa trên URL\n",
    "def create_filename(url, query):\n",
    "    # Tạo tên file từ search_query và một phần của URL để tránh trùng lặp\n",
    "    url_hash = hashlib.md5(url.encode()).hexdigest()[:8]\n",
    "    # Lấy phần mở rộng của file từ URL gốc\n",
    "    ext = os.path.splitext(urlparse(url).path)[1]\n",
    "    if not ext:\n",
    "        ext = '.jpg'  # Mặc định là .jpg nếu không có phần mở rộng\n",
    "    # Tạo tên file an toàn từ search_query\n",
    "    safe_query = \"\".join(c if c.isalnum() or c in (' ', '_') else '_' for c in query)\n",
    "    safe_query = safe_query.strip().replace(' ', '_')\n",
    "    return f\"{safe_query}_{url_hash}{ext}\"\n",
    "\n",
    "# Tải ảnh và cập nhật local_path\n",
    "success_count = 0\n",
    "for idx, row in tqdm(sample_df.iterrows(), total=len(sample_df), desc=\"Đang tải ảnh\"):\n",
    "    url = row['original_url']\n",
    "    query = row['search_query'] if pd.notna(row['search_query']) else 'unknown'\n",
    "    \n",
    "    # Tạo tên file mới\n",
    "    filename = create_filename(url, query)\n",
    "    save_path = os.path.join(image_dir, filename)\n",
    "    \n",
    "    # Tải ảnh\n",
    "    if download_image(url, save_path):\n",
    "        # Cập nhật local_path trong DataFrame\n",
    "        sample_df.at[idx, 'local_path'] = save_path\n",
    "        success_count += 1\n",
    "    \n",
    "    # Thêm delay nhỏ để tránh quá tải server\n",
    "    time.sleep(0.3)\n",
    "\n",
    "print(f\"\\nĐã tải thành công {success_count}/200 ảnh\")\n",
    "\n",
    "# Hiển thị một vài ví dụ về đường dẫn mới\n",
    "print(\"\\nVí dụ về các đường dẫn local mới:\")\n",
    "print(sample_df['local_path'].head())\n",
    "\n",
    "# Lưu DataFrame đã cập nhật\n",
    "sample_df.to_csv('updated_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Đang tải ảnh: 100%|██████████| 300/300 [07:49<00:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== THỐNG KÊ KẾT QUẢ TẢI ẢNH ===\n",
      "Tổng số URL: 300\n",
      "Số URL thành công: 293\n",
      "Số URL thất bại: 7\n",
      "\n",
      "=== CHI TIẾT LỖI ===\n",
      "Không phải file ảnh: 3 URLs\n",
      "Timeout: 2 URLs\n",
      "Lỗi HTTP 404: 1 URLs\n",
      "Lỗi SSL: 1 URLs\n",
      "\n",
      "=== THÔNG TIN DATASET SAU KHI LỌC ===\n",
      "Kích thước ban đầu: (300, 6)\n",
      "Kích thước sau khi lọc: (293, 6)\n",
      "\n",
      "Phân bố dữ liệu theo source_website:\n",
      "source_website\n",
      "Báo Tuổi Trẻ          9\n",
      "Báo Lao động          8\n",
      "Báo Thanh Niên        7\n",
      "baotintuc.vn          7\n",
      "Thư Viện Pháp Luật    7\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "import warnings\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# Tạo thư mục để lưu ảnh nếu chưa tồn tại\n",
    "image_dir = './images'\n",
    "if not os.path.exists(image_dir):\n",
    "    os.makedirs(image_dir)\n",
    "\n",
    "def download_image(url, save_path, max_retries=3):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                url,\n",
    "                headers=headers,\n",
    "                timeout=15,\n",
    "                verify=False,\n",
    "                stream=True\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                if 'image' in response.headers.get('content-type', ''):\n",
    "                    with open(save_path, 'wb') as f:\n",
    "                        for chunk in response.iter_content(chunk_size=8192):\n",
    "                            if chunk:\n",
    "                                f.write(chunk)\n",
    "                    return True, None\n",
    "                else:\n",
    "                    return False, \"Không phải file ảnh\"\n",
    "            else:\n",
    "                return False, f\"Lỗi HTTP {response.status_code}\"\n",
    "                \n",
    "        except requests.exceptions.SSLError:\n",
    "            if attempt == max_retries - 1:\n",
    "                return False, \"Lỗi SSL\"\n",
    "        except requests.exceptions.Timeout:\n",
    "            if attempt == max_retries - 1:\n",
    "                return False, \"Timeout\"\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            if attempt == max_retries - 1:\n",
    "                return False, \"Lỗi kết nối\"\n",
    "            time.sleep(2)\n",
    "        except Exception as e:\n",
    "            return False, f\"Lỗi không xác định: {str(e)}\"\n",
    "    \n",
    "    return False, f\"Thất bại sau {max_retries} lần thử\"\n",
    "\n",
    "# Lấy 500 ảnh đầu tiên để demo\n",
    "sample_df = final_df.head(300).copy()\n",
    "\n",
    "# Dictionary để lưu thống kê lỗi\n",
    "error_stats = {}\n",
    "failed_urls = []\n",
    "success_count = 0\n",
    "\n",
    "# Tải ảnh và theo dõi kết quả\n",
    "for idx, row in tqdm(sample_df.iterrows(), total=len(sample_df), desc=\"Đang tải ảnh\"):\n",
    "    url = row['original_url']\n",
    "    query = row['search_query'] if pd.notna(row['search_query']) else 'unknown'\n",
    "    \n",
    "    filename = create_filename(url, query)\n",
    "    save_path = os.path.join(image_dir, filename)\n",
    "    \n",
    "    success, error_message = download_image(url, save_path)\n",
    "    \n",
    "    if success:\n",
    "        sample_df.at[idx, 'local_path'] = save_path\n",
    "        success_count += 1\n",
    "    else:\n",
    "        failed_urls.append((url, error_message))\n",
    "        error_stats[error_message] = error_stats.get(error_message, 0) + 1\n",
    "    \n",
    "    time.sleep(0.3)\n",
    "\n",
    "# Lọc bỏ các dòng có URL thất bại\n",
    "failed_url_list = [url for url, _ in failed_urls]\n",
    "sample_df_clean = sample_df[~sample_df['original_url'].isin(failed_url_list)]\n",
    "\n",
    "# Thống kê kết quả\n",
    "print(\"\\n=== THỐNG KÊ KẾT QUẢ TẢI ẢNH ===\")\n",
    "print(f\"Tổng số URL: {len(sample_df)}\")\n",
    "print(f\"Số URL thành công: {success_count}\")\n",
    "print(f\"Số URL thất bại: {len(failed_urls)}\")\n",
    "\n",
    "print(\"\\n=== CHI TIẾT LỖI ===\")\n",
    "for error_type, count in error_stats.items():\n",
    "    print(f\"{error_type}: {count} URLs\")\n",
    "\n",
    "print(\"\\n=== THÔNG TIN DATASET SAU KHI LỌC ===\")\n",
    "print(f\"Kích thước ban đầu: {sample_df.shape}\")\n",
    "print(f\"Kích thước sau khi lọc: {sample_df_clean.shape}\")\n",
    "print(\"\\nPhân bố dữ liệu theo source_website:\")\n",
    "print(sample_df_clean['source_website'].value_counts().head())\n",
    "\n",
    "# Lưu danh sách URL thất bại để kiểm tra\n",
    "with open('failed_urls.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"URL,Lỗi\\n\")  # Header\n",
    "    for url, error in failed_urls:\n",
    "        f.write(f\"{url},{error}\\n\")\n",
    "\n",
    "# Lưu DataFrame đã được lọc\n",
    "sample_df_clean.to_csv('cleaned_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import urllib3\n",
    "import time  \n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "def check_image_url(url, max_retries=2):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Chỉ gửi HEAD request để kiểm tra metadata, không tải nội dung\n",
    "            response = requests.head(\n",
    "                url,\n",
    "                headers=headers,\n",
    "                timeout=5,  # Giảm timeout xuống vì chỉ check metadata\n",
    "                verify=False,\n",
    "                allow_redirects=True\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                content_type = response.headers.get('content-type', '')\n",
    "                if 'image' in content_type:\n",
    "                    return True, None\n",
    "                else:\n",
    "                    return False, \"Không phải file ảnh\"\n",
    "            else:\n",
    "                return False, f\"Lỗi HTTP {response.status_code}\"\n",
    "                \n",
    "        except requests.exceptions.SSLError:\n",
    "            if attempt == max_retries - 1:\n",
    "                return False, \"Lỗi SSL\"\n",
    "        except requests.exceptions.Timeout:\n",
    "            if attempt == max_retries - 1:\n",
    "                return False, \"Timeout\"\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            if attempt == max_retries - 1:\n",
    "                return False, \"Lỗi kết nối\"\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            return False, f\"Lỗi không xác định: {str(e)}\"\n",
    "    \n",
    "    return False, f\"Thất bại sau {max_retries} lần thử\"\n",
    "\n",
    "# Kiểm tra toàn bộ dataset\n",
    "error_stats = {}\n",
    "failed_urls = []\n",
    "success_count = 0\n",
    "\n",
    "# Kiểm tra URLs\n",
    "for idx, row in tqdm(final_df.iterrows(), total=len(final_df), desc=\"Đang kiểm tra URLs\"):\n",
    "    url = row['original_url']\n",
    "    success, error_message = check_image_url(url)\n",
    "    \n",
    "    if success:\n",
    "        success_count += 1\n",
    "    else:\n",
    "        failed_urls.append((url, error_message))\n",
    "        error_stats[error_message] = error_stats.get(error_message, 0) + 1\n",
    "    \n",
    "    # Thêm delay nhỏ để tránh quá tải server\n",
    "    time.sleep(0.1)\n",
    "\n",
    "# Lọc bỏ các URL thất bại\n",
    "failed_url_list = [url for url, _ in failed_urls]\n",
    "clean_df = final_df[~final_df['original_url'].isin(failed_url_list)]\n",
    "\n",
    "# Thống kê kết quả\n",
    "print(\"\\n=== THỐNG KÊ KẾT QUẢ KIỂM TRA URL ===\")\n",
    "print(f\"Tổng số URL: {len(final_df)}\")\n",
    "print(f\"Số URL hợp lệ: {success_count}\")\n",
    "print(f\"Số URL không hợp lệ: {len(failed_urls)}\")\n",
    "\n",
    "print(\"\\n=== CHI TIẾT LỖI ===\")\n",
    "for error_type, count in error_stats.items():\n",
    "    print(f\"{error_type}: {count} URLs\")\n",
    "\n",
    "print(\"\\n=== THÔNG TIN DATASET SAU KHI LỌC ===\")\n",
    "print(f\"Kích thước ban đầu: {final_df.shape}\")\n",
    "print(f\"Kích thước sau khi lọc: {clean_df.shape}\")\n",
    "print(\"\\nPhân bố dữ liệu theo source_website:\")\n",
    "print(clean_df['source_website'].value_counts().head())\n",
    "\n",
    "# Lưu danh sách URL thất bại\n",
    "with open('invalid_urls.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"URL,Lỗi\\n\")\n",
    "    for url, error in failed_urls:\n",
    "        f.write(f\"{url},{error}\\n\")\n",
    "\n",
    "# Lưu DataFrame đã được lọc\n",
    "clean_df.to_csv('valid_urls_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "annotate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
